# Configuration for PRISM model placement - Ablation: Adaptive Exploration Ratio
# This config enables adaptive exploration ratio to dynamically adjust
# exploration/exploitation balance based on recent improvement rate.
max_iterations: 20
checkpoint_interval: 1
log_level: "INFO"

# LLM configuration
llm:
  primary_model: "gpt-5"
  api_base: "https://api.openai.com/v1"
  primary_model_weight: 1.0
  temperature: 0.7
  top_p: 0.95
  max_tokens: 32000
  timeout: 600

# Prompt configuration
prompt:
  system_message: "You are an expert for model placement on GPUs. Your task is to improve a model placement algorithm by improve the function named compute_model_placement in the intial program that places models to available GPUs. 
  The algorithm must MINIMIZE the maximum KVPR across all GPUs while ensuring models can fit into the GPUs' memory. Note that KVPR is KV cache pressure for a GPU. It indicates how crowded a GPU is. For a specific GPU, its KVPR is computed as sum(model.req_rate/model.slo for model in models) / (GPU_MEM_SIZE - sum(model.model_size for model in models)), where models are the models on this GPU. The generated program should be as simple as possible and the code should be executed correctly without errors."
  num_top_programs: 3
  use_template_stochasticity: true

# Database configuration - WITH ADAPTIVE EXPLORATION
database:
  population_size: 80
  archive_size: 30
  num_islands: 4
  elite_selection_ratio: 0.15
  exploration_ratio: 0.2  # Base exploration ratio (will be dynamically adjusted)
  exploitation_ratio: 0.65
  
  # ADAPTIVE EXPLORATION SETTINGS (ablation feature)
  use_adaptive_search: true
  adaptive_window_size: 20        # Look at last 20 iterations for stability
  adaptive_min_exploration: 0.1   # Minimum exploration ratio
  adaptive_max_exploration: 0.7   # Maximum exploration ratio

# Evaluator configuration
evaluator:
  timeout: 90
  cascade_evaluation: false
  cascade_thresholds: [0.3, 0.6]
  parallel_evaluations: 4
  use_llm_feedback: false

# Evolution settings
diff_based_evolution: true
max_code_length: 60000

