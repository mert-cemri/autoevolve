# Best of N Search Configuration

# Search parameters
n: 4                    # Number of parallel lineages
iterations: 10          # Number of iterations per lineage

# Evaluation parameters
num_eval_problems: 10   # Number of problems to evaluate on (randomly sampled with seed=42)

# LLM configuration
model: "gpt-5"            # Model for search/evolution (mutating programs)
agent_model: "gpt-5-mini" # Model for multi-agent system (solving problems)
temperature: 0.8          # For models that support it (auto-handled)
max_tokens: 16000         # Auto-converted to max_completion_tokens

# Paths
initial_program: "initial_program.py"
evaluator: "evaluator.py"
# output_dir is auto-generated: custom_search/results/best_of_n/run_{timestamp}
