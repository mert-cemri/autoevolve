# Configuration for function minimization example
max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"

max_code_length: 65536

# LLM configuration
llm:
  primary_model: "gpt-5"
  api_base: "https://api.openai.com/v1"
  primary_model_weight: 1.0
  temperature: 0.7
  top_p: 0.95
  max_tokens: 32000
  timeout: 900

# Prompt configuration
prompt:
  system_message: "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.

  This algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.

  Your goal will be two-fold:
  1. Improve the algorithm to achieve better load balancing; while
  2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.
  
  The current algorithm is implemented in the `rebalance_experts` function.
  "
  num_top_programs: 3
  use_template_stochasticity: true

# Database configuration
database:
  population_size: 1000
  archive_size: 100
  num_islands: 5
  migration_interval: 50
  migration_rate: 0.1
  elite_selection_ratio: 0.1
  exploration_ratio: 0.2
  exploitation_ratio: 0.7
  feature_dimensions:
    - "score"
    - "complexity"
  feature_bins: 10

  # Adaptive exploration settings
  use_adaptive_search: true
  adaptive_window_size: 20
  adaptive_min_exploration: 0.1
  adaptive_max_exploration: 0.7

  # Softmax sampling for exploitation
  exploitation_temperature: 1.0  # Controls sharpness of softmax (lower = more greedy)

  # Stagnation detection and multi-child generation
  stagnation_threshold: 10  # Iterations without improvement to trigger stagnation
  stagnation_multi_child_count: 3  # Number of diverse children to generate on stagnation

  # Sibling context for prompts
  sibling_context_limit: 5  # Number of previous children to show in prompt
  
# Evaluator configuration
evaluator:
  timeout: 60
  parallel_evaluations: 4
  use_llm_feedback: false

# Evolution settings
diff_based_evolution: true
allow_full_rewrites: false
